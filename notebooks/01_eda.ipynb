{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5e0b38",
   "metadata": {},
   "source": [
    "### importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f623f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52de9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6122b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324353a8",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "79e31322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.175161e-15</td>\n",
       "      <td>3.384974e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.094852e-15</td>\n",
       "      <td>1.021879e-15</td>\n",
       "      <td>1.494498e-15</td>\n",
       "      <td>-5.620335e-16</td>\n",
       "      <td>1.149614e-16</td>\n",
       "      <td>-2.414189e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628620e-16</td>\n",
       "      <td>-3.576577e-16</td>\n",
       "      <td>2.618565e-16</td>\n",
       "      <td>4.473914e-15</td>\n",
       "      <td>5.109395e-16</td>\n",
       "      <td>1.686100e-15</td>\n",
       "      <td>-3.661401e-16</td>\n",
       "      <td>-1.227452e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.175161e-15  3.384974e-16 -1.379537e-15  2.094852e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.021879e-15  1.494498e-15 -5.620335e-16  1.149614e-16 -2.414189e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.628620e-16 -3.576577e-16  2.618565e-16  4.473914e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.109395e-16  1.686100e-15 -3.661401e-16 -1.227452e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "df.info()\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8ee57",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66ad48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values per column\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "duplicated rows\n",
      "1081\n"
     ]
    }
   ],
   "source": [
    "print(\"missing values per column\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"duplicated rows\")\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4bfef",
   "metadata": {},
   "source": [
    "### checking for class imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7bb7dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    99.827251\n",
      "1     0.172749\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['Class'].value_counts())\n",
    "\n",
    "print(df['Class'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6362e",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d697dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
      "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
      "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
      "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
      "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
      "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
      "\n",
      "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
      "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
      "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
      "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
      "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
      "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
      "\n",
      "        V23       V24       V25       V26       V27       V28  Class  \n",
      "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
      "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
      "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
      "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
      "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "# Scale and create the new columns directly\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "# Drop the old columns\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "if 'scaled_amount' not in df.columns[:2]:\n",
    "    scaled_amount = df['scaled_amount']\n",
    "    scaled_time = df['scaled_time']\n",
    "    \n",
    "    df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "    df.insert(0, 'scaled_amount', scaled_amount)\n",
    "    df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b7d35",
   "metadata": {},
   "source": [
    "### undersampling the data inorder to balance legitimate and fraud transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6e4fc5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (199364, 30)\n",
      "Val Shape: (42721, 30)\n",
      "Test Shape: (42722, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# Split into Train and Test \n",
    "df = df.sort_values('scaled_time')\n",
    "\n",
    "n = len(df)\n",
    "train_end = int(n * 0.7)    # First 70% for Training\n",
    "val_end = int(n * 0.85)     # Next 15% for Validation\n",
    "\n",
    "train_df = df.iloc[:train_end]\n",
    "val_df = df.iloc[train_end:val_end]\n",
    "test_df = df.iloc[val_end:]\n",
    "\n",
    "# Defining X and y for all three sets\n",
    "X_train, y_train = train_df.drop('Class', axis=1), train_df['Class']\n",
    "X_val, y_val = val_df.drop('Class', axis=1), val_df['Class']\n",
    "X_test, y_test = test_df.drop('Class', axis=1), test_df['Class']\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Val Shape: {X_val.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d8155fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, average_precision_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, X, y, name=\"Model\"):\n",
    "    preds = model.predict(X)\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Calculate Average Precision\n",
    "    ap_score = average_precision_score(y, probs)\n",
    "    \n",
    "    print(f\"Average Precision (PR-AUC): {ap_score:.4f}\")\n",
    "    \n",
    "    # Report precision, recall,F1 \n",
    "    print(classification_report(y, preds))\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, preds))\n",
    "    \n",
    "    return ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e317c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "#separating fraud and non fraud classes\n",
    "fraud_df = train_data[train_data['Class'] == 1]\n",
    "non_fraud_df = train_data[train_data['Class'] == 0]\n",
    "\n",
    "non_fraud_sampled = non_fraud_df.sample(n=len(fraud_df), random_state= 42)\n",
    "\n",
    "# concatinating the datasets\n",
    "balanced_df = pd.concat([fraud_df, non_fraud_sampled])\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
    "\n",
    "X_train_balanced = balanced_df.drop('Class', axis=1)\n",
    "y_train_balanced = balanced_df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3bec28af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Training Shape: (768, 30)\n",
      "Balanced Training Class Counts:\n",
      " Class\n",
      "0    384\n",
      "1    384\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBalanced Training Shape:\", X_train_balanced.shape)\n",
    "print(\"Balanced Training Class Counts:\\n\", y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253da27d",
   "metadata": {},
   "source": [
    "### fraud detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf837f",
   "metadata": {},
   "source": [
    "#### logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ae4170f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression (Validation) ---\n",
      "Average Precision (PR-AUC): 0.7205\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42665\n",
      "           1       0.04      0.91      0.08        56\n",
      "\n",
      "    accuracy                           0.97     42721\n",
      "   macro avg       0.52      0.94      0.53     42721\n",
      "weighted avg       1.00      0.97      0.98     42721\n",
      "\n",
      "\n",
      "Top 5 Features by Absolute Coefficient:\n",
      "   Feature  Coefficient  Abs_Coef\n",
      "23     V22     0.906513  0.906513\n",
      "13     V12    -0.885412  0.885412\n",
      "5       V4     0.866247  0.866247\n",
      "15     V14    -0.744451  0.744451\n",
      "9       V8    -0.703492  0.703492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# Initialize and Train\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# 2. Evaluate on VALIDATION SET\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_probs = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# 3. Report PR-AUC\n",
    "val_ap = average_precision_score(y_val, y_val_probs)\n",
    "\n",
    "print(f\"--- Logistic Regression (Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Feature Analysis\n",
    "feature_names = X_train.columns\n",
    "lr_coefs = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': model.coef_[0]\n",
    "})\n",
    "lr_coefs['Abs_Coef'] = lr_coefs['Coefficient'].abs()\n",
    "lr_coefs = lr_coefs.sort_values(by='Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Features by Absolute Coefficient:\")\n",
    "print(lr_coefs.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d53315a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "951a9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest (Validation) ---\n",
      "Average Precision (PR-AUC): 0.8513\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     42665\n",
      "           1       0.04      0.91      0.08        56\n",
      "\n",
      "    accuracy                           0.97     42721\n",
      "   macro avg       0.52      0.94      0.53     42721\n",
      "weighted avg       1.00      0.97      0.98     42721\n",
      "\n",
      "\n",
      "Top 5 Feature Importances (Random Forest):\n",
      "   Feature  Importance\n",
      "15     V14    0.193772\n",
      "13     V12    0.158323\n",
      "5       V4    0.088543\n",
      "11     V10    0.085825\n",
      "12     V11    0.077286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# Initialize and Train\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate on VALIDATION SET\n",
    "y_val_pred_rf = rf.predict(X_val)\n",
    "y_val_probs_rf = rf.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Report PR-AUC\n",
    "val_ap_rf = average_precision_score(y_val, y_val_probs_rf)\n",
    "\n",
    "print(f\"--- Random Forest (Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_rf:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "\n",
    "# Feature Analysis\n",
    "rf_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Feature Importances (Random Forest):\")\n",
    "print(rf_importances.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287efba9",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6b65e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost (Validation) ---\n",
      "Average Precision (PR-AUC): 0.8165\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     42665\n",
      "           1       0.04      0.91      0.07        56\n",
      "\n",
      "    accuracy                           0.97     42721\n",
      "   macro avg       0.52      0.94      0.53     42721\n",
      "weighted avg       1.00      0.97      0.98     42721\n",
      "\n",
      "\n",
      "Top 5 Feature Importances (XGBoost):\n",
      "   Feature  Importance\n",
      "15     V14    0.533226\n",
      "11     V10    0.063553\n",
      "5       V4    0.046770\n",
      "13     V12    0.043451\n",
      "21     V20    0.026281\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# Initialize and Train\n",
    "xgb = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate on VALIDATION SET\n",
    "y_val_pred_xgb = xgb.predict(X_val)\n",
    "y_val_probs_xgb = xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Report PR-AUC\n",
    "val_ap_xgb = average_precision_score(y_val, y_val_probs_xgb)\n",
    "\n",
    "print(f\"--- XGBoost (Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_xgb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "\n",
    "# Feature Analysis\n",
    "xgb_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Feature Importances (XGBoost):\")\n",
    "print(xgb_importances.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be76227",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1197ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Naive Bayes (Validation) ---\n",
      "Average Precision (PR-AUC): 0.0481\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     42665\n",
      "           1       0.04      0.88      0.07        56\n",
      "\n",
      "    accuracy                           0.97     42721\n",
      "   macro avg       0.52      0.92      0.53     42721\n",
      "weighted avg       1.00      0.97      0.98     42721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# Initialize and Train\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "#  Evaluate on VALIDATION SET\n",
    "y_val_pred_gnb = gnb.predict(X_val)\n",
    "y_val_probs_gnb = gnb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Report PR-AUC\n",
    "val_ap_gnb = average_precision_score(y_val, y_val_probs_gnb)\n",
    "\n",
    "print(f\"--- Naive Bayes (Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_gnb:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ee8360",
   "metadata": {},
   "source": [
    "Logistic Regression (Undersampled)\n",
    "Recall (Fraud)    : 0.92\n",
    "Precision (Fraud) : 0.04\n",
    "False Positives   : 2,252\n",
    "\n",
    "Random Forest (Undersampled)\n",
    "Recall (Fraud)    : 0.91\n",
    "Precision (Fraud) : 0.04\n",
    "False Positives   : 2,179\n",
    "\n",
    "Naive Bayes (Undersampled)\n",
    "Recall (Fraud)    : 0.88\n",
    "Precision (Fraud) : 0.04\n",
    "False Positives   : ~2,300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f0211",
   "metadata": {},
   "source": [
    "undersampling the data set consistently gave high recall across various models but had a very poor precision indicating a high number of false triggers. Therefore trying SMOTE to oversampling to see how the models perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73477127",
   "metadata": {},
   "source": [
    "### Over Sampling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5b4b5153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (199364, 30)\n",
      "SMOTE Train Shape:    (397960, 30)\n",
      "\n",
      "New Class Distribution:\n",
      "Class\n",
      "0    198980\n",
      "1    198980\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "# Fitting SMOTE to trainign data\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Checking the new sizes\n",
    "print(f\"Original Train Shape: {X_train.shape}\")\n",
    "print(f\"SMOTE Train Shape:    {X_train_sm.shape}\")\n",
    "print(f\"\\nNew Class Distribution:\\n{y_train_sm.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738fca3",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0256db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression (SMOTE - Validation) ---\n",
      "Average Precision (PR-AUC): 0.8461\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     42665\n",
      "           1       0.06      0.93      0.11        56\n",
      "\n",
      "    accuracy                           0.98     42721\n",
      "   macro avg       0.53      0.95      0.55     42721\n",
      "weighted avg       1.00      0.98      0.99     42721\n",
      "\n",
      "\n",
      "Top 5 Features by Absolute Coefficient:\n",
      "   Feature  Coefficient  Abs_Coef\n",
      "15     V14    -1.228806  1.228806\n",
      "21     V20    -1.228422  1.228422\n",
      "13     V12    -1.044372  1.044372\n",
      "11     V10    -0.927538  0.927538\n",
      "5       V4     0.908529  0.908529\n"
     ]
    }
   ],
   "source": [
    "lr_sm = LogisticRegression(max_iter=1000)\n",
    "lr_sm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_val_pred_lr_sm = lr_sm.predict(X_val)\n",
    "y_val_probs_lr_sm = lr_sm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_ap_lr_sm = average_precision_score(y_val, y_val_probs_lr_sm)\n",
    "\n",
    "print(f\"--- Logistic Regression (SMOTE - Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_lr_sm:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_lr_sm))\n",
    "\n",
    "lr_sm_coefs = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr_sm.coef_[0]\n",
    "})\n",
    "lr_sm_coefs['Abs_Coef'] = lr_sm_coefs['Coefficient'].abs()\n",
    "lr_sm_coefs = lr_sm_coefs.sort_values(by='Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Features by Absolute Coefficient:\")\n",
    "print(lr_sm_coefs.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e40c0e",
   "metadata": {},
   "source": [
    "### Random Forest (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0e08a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest (SMOTE - Validation) ---\n",
      "Average Precision (PR-AUC): 0.8564\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42665\n",
      "           1       0.82      0.80      0.81        56\n",
      "\n",
      "    accuracy                           1.00     42721\n",
      "   macro avg       0.91      0.90      0.91     42721\n",
      "weighted avg       1.00      1.00      1.00     42721\n",
      "\n",
      "\n",
      "Top 5 Feature Importances (Random Forest SMOTE):\n",
      "   Feature  Importance\n",
      "15     V14    0.215982\n",
      "13     V12    0.154377\n",
      "5       V4    0.101623\n",
      "11     V10    0.092431\n",
      "12     V11    0.083540\n"
     ]
    }
   ],
   "source": [
    "rf_sm = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42)\n",
    "rf_sm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_val_pred_rf_sm = rf_sm.predict(X_val)\n",
    "y_val_probs_rf_sm = rf_sm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_ap_rf_sm = average_precision_score(y_val, y_val_probs_rf_sm)\n",
    "\n",
    "print(f\"--- Random Forest (SMOTE - Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_rf_sm:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_rf_sm))\n",
    "\n",
    "rf_sm_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_sm.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Feature Importances (Random Forest SMOTE):\")\n",
    "print(rf_sm_importances.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95b2b5",
   "metadata": {},
   "source": [
    "### XGBoost (with SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "16554b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost (SMOTE - Validation) ---\n",
      "Average Precision (PR-AUC): 0.8278\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42665\n",
      "           1       0.92      0.79      0.85        56\n",
      "\n",
      "    accuracy                           1.00     42721\n",
      "   macro avg       0.96      0.89      0.92     42721\n",
      "weighted avg       1.00      1.00      1.00     42721\n",
      "\n",
      "\n",
      "Top 5 Feature Importances (XGBoost SMOTE):\n",
      "   Feature  Importance\n",
      "15     V14    0.605640\n",
      "5       V4    0.046145\n",
      "13     V12    0.035746\n",
      "11     V10    0.030946\n",
      "9       V8    0.026680\n"
     ]
    }
   ],
   "source": [
    "xgb_sm = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "xgb_sm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_val_pred_xgb_sm = xgb_sm.predict(X_val)\n",
    "y_val_probs_xgb_sm = xgb_sm.predict_proba(X_val)[:, 1]\n",
    "\n",
    "val_ap_xgb_sm = average_precision_score(y_val, y_val_probs_xgb_sm)\n",
    "\n",
    "print(f\"--- XGBoost (SMOTE - Validation) ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_xgb_sm:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_val_pred_xgb_sm))\n",
    "\n",
    "xgb_sm_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb_sm.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Feature Importances (XGBoost SMOTE):\")\n",
    "print(xgb_sm_importances.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475eeac6",
   "metadata": {},
   "source": [
    "XGBoost is the best performer so far with smote. While it missed slightly more fraud than the Logistic Regression model, it reduced the False Positive count from thousands to just 33."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9339c",
   "metadata": {},
   "source": [
    "### Pipeline for XGBOOST + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "14e5689f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FINAL PIPELINE: VALIDATION RESULTS ---\n",
      "Average Precision (PR-AUC): 0.8271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42665\n",
      "           1       0.86      0.77      0.81        56\n",
      "\n",
      "    accuracy                           1.00     42721\n",
      "   macro avg       0.93      0.88      0.91     42721\n",
      "weighted avg       1.00      1.00      1.00     42721\n",
      "\n",
      "\n",
      "--- FINAL PIPELINE: TEST RESULTS ---\n",
      "Final Average Precision (PR-AUC): 0.7675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     42670\n",
      "           1       0.72      0.75      0.74        52\n",
      "\n",
      "    accuracy                           1.00     42722\n",
      "   macro avg       0.86      0.87      0.87     42722\n",
      "weighted avg       1.00      1.00      1.00     42722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.metrics import classification_report, average_precision_score, confusion_matrix\n",
    "\n",
    "# Defining the Pipeline Architecture\n",
    "final_pipeline = imbpipeline(steps=[\n",
    "    ('scaler', RobustScaler()),          \n",
    "    ('smote', SMOTE(random_state=42)),   \n",
    "    ('xgb', XGBClassifier(               \n",
    "        eval_metric='logloss', \n",
    "        random_state=42,\n",
    "        n_jobs=-1                 \n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit to the training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 3. Evaluating on validation\n",
    "y_val_pred_final = final_pipeline.predict(X_val)\n",
    "y_val_probs_final = final_pipeline.predict_proba(X_val)[:, 1]\n",
    "val_ap_final = average_precision_score(y_val, y_val_probs_final)\n",
    "\n",
    "print(\"--- FINAL PIPELINE: VALIDATION RESULTS ---\")\n",
    "print(f\"Average Precision (PR-AUC): {val_ap_final:.4f}\")\n",
    "print(classification_report(y_val, y_val_pred_final))\n",
    "\n",
    "# final test \n",
    "y_test_pred_final = final_pipeline.predict(X_test)\n",
    "y_test_probs_final = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "test_ap_final = average_precision_score(y_test, y_test_probs_final)\n",
    "\n",
    "print(\"\\n--- FINAL PIPELINE: TEST RESULTS ---\")\n",
    "print(f\"Final Average Precision (PR-AUC): {test_ap_final:.4f}\")\n",
    "print(classification_report(y_test, y_test_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9526b",
   "metadata": {},
   "source": [
    "### Model Comparision Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "25cf7544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PR-AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest (SMOTE)</th>\n",
       "      <td>0.856425</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Undersampled)</th>\n",
       "      <td>0.851320</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.076462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic (SMOTE)</th>\n",
       "      <td>0.846140</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.113786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost (SMOTE)</th>\n",
       "      <td>0.827834</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost (Undersampled)</th>\n",
       "      <td>0.816474</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.069341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic (Undersampled)</th>\n",
       "      <td>0.720493</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.077331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                PR-AUC  Precision    Recall  F1-Score\n",
       "Random Forest (SMOTE)         0.856425   0.818182  0.803571  0.810811\n",
       "Random Forest (Undersampled)  0.851320   0.039906  0.910714  0.076462\n",
       "Logistic (SMOTE)              0.846140   0.060606  0.928571  0.113786\n",
       "XGBoost (SMOTE)               0.827834   0.916667  0.785714  0.846154\n",
       "XGBoost (Undersampled)        0.816474   0.036042  0.910714  0.069341\n",
       "Logistic (Undersampled)       0.720493   0.040380  0.910714  0.077331"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def get_metrics(model, X, y):\n",
    "    preds = model.predict(X)\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    return {\n",
    "        'PR-AUC': average_precision_score(y, probs),\n",
    "        'Precision': precision_score(y, preds),\n",
    "        'Recall': recall_score(y, preds),\n",
    "        'F1-Score': f1_score(y, preds)\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    'Logistic (Undersampled)': get_metrics(model, X_val, y_val),\n",
    "    'Random Forest (Undersampled)': get_metrics(rf, X_val, y_val),\n",
    "    'XGBoost (Undersampled)': get_metrics(xgb, X_val, y_val),\n",
    "    'Logistic (SMOTE)': get_metrics(lr_sm, X_val, y_val),\n",
    "    'Random Forest (SMOTE)': get_metrics(rf_sm, X_val, y_val),\n",
    "    'XGBoost (SMOTE)': get_metrics(xgb_sm, X_val, y_val)\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df = comparison_df.sort_values(by='PR-AUC', ascending=False)\n",
    "\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486bc1d",
   "metadata": {},
   "source": [
    "\"We chose the XGBoost + SMOTE pipeline as our production model because it achieved the highest Average Precision on the validation set, demonstrating a superior ability to identify fraudulent transactions in a chronological, real-world scenario.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
